{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":9133503,"sourceType":"datasetVersion","datasetId":5514850}],"dockerImageVersionId":30746,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# TASK 1 Implement a Neural Network on the Fashion MNIST dataset ","metadata":{}},{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Conv2D, MaxPooling2D, UpSampling2D, Flatten, Dense, Dropout, BatchNormalization, Reshape\nfrom keras.utils import to_categorical\nimport matplotlib.pyplot as plt\nfrom sklearn.metrics import classification_report\nfrom sklearn.metrics import confusion_matrix\nimport seaborn as sns\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-08-11T01:47:31.009491Z","iopub.execute_input":"2024-08-11T01:47:31.009833Z","iopub.status.idle":"2024-08-11T01:47:44.425896Z","shell.execute_reply.started":"2024-08-11T01:47:31.009803Z","shell.execute_reply":"2024-08-11T01:47:44.424896Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Importing both training and testing dataset in csv files as dataframes","metadata":{}},{"cell_type":"code","source":"train = pd.read_csv('/kaggle/input/fashionmnist-dsc/fashion-mnist_train.csv')\ntest = pd.read_csv('/kaggle/input/fashionmnist-dsc/fashion-mnist_test.csv')","metadata":{"execution":{"iopub.status.busy":"2024-08-11T01:47:44.429257Z","iopub.execute_input":"2024-08-11T01:47:44.429788Z","iopub.status.idle":"2024-08-11T01:47:51.184186Z","shell.execute_reply.started":"2024-08-11T01:47:44.429760Z","shell.execute_reply":"2024-08-11T01:47:51.183230Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Initial Analysis","metadata":{}},{"cell_type":"markdown","source":"## Checking the dimensions of training and testing dataframes","metadata":{}},{"cell_type":"code","source":"train.shape","metadata":{"execution":{"iopub.status.busy":"2024-08-11T01:47:51.185277Z","iopub.execute_input":"2024-08-11T01:47:51.185561Z","iopub.status.idle":"2024-08-11T01:47:51.191958Z","shell.execute_reply.started":"2024-08-11T01:47:51.185538Z","shell.execute_reply":"2024-08-11T01:47:51.191112Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test.shape","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Training dataset has 60000 images in 28x28 format of black and white meanwhile testing dataset has 10000 images of same format","metadata":{}},{"cell_type":"code","source":"train.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test.head(1)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Target variable analysis","metadata":{}},{"cell_type":"code","source":"train['label'].unique()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test['label'].unique()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### There are difference in labels for both training and testing dataset meanwhile both are 10 classes variables\n### Hence the target variable has 10 classes","metadata":{}},{"cell_type":"markdown","source":"## Splitting of target variable from both training and testing dataset","metadata":{}},{"cell_type":"code","source":"ytrain,ytest = train.label, test.label\ntrain.drop(columns = 'label', inplace = True)\ntest.drop(columns = 'label', inplace = True)\nytrain_tf = to_categorical(ytrain, num_classes=10)\nytest_tf = to_categorical(ytest, num_classes=10)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Sample images","metadata":{}},{"cell_type":"code","source":"yt3 = np.argmax(ytrain_tf[:3], axis=1)\nimages = train.values[:3].reshape(-1, 28, 28)\nplt.figure(figsize=(12, 4))\nfor i in range(3):\n    plt.subplot(1, 3, i+1)\n    plt.imshow(images[i], cmap='gray')\n    plt.title(f'Label: {yt3[i]}')\n    plt.axis('off')\nplt.show()\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Building Convolutional Neural Network","metadata":{}},{"cell_type":"markdown","source":"## Constructing CNN Model\n>This CNN model architecture processes 28x28 images through three convolutional layers, each followed by batch normalization, max pooling, and dropout for regularization. It includes an upscaling layer to increase feature map resolution before flattening and passing the data through two fully connected layers. The final output layer uses softmax activation to classify the images into one of 10 categories.","metadata":{}},{"cell_type":"code","source":"model = Sequential()\n\n# Reshaping the input vector into 28x28x1\nmodel.add(Reshape((28, 28, 1), input_shape=(784,)))\n\n# Initial Layer\nmodel.add(Conv2D(32, (3, 3), activation='relu'))\nmodel.add(BatchNormalization())\nmodel.add(MaxPooling2D(pool_size=(2, 2)))\nmodel.add(Dropout(0.2))\n\n# Upscaling Layer\nmodel.add(UpSampling2D(size=(2, 2)))\n\n#2nd Layer\nmodel.add(Conv2D(64, (3, 3), activation='relu'))\nmodel.add(BatchNormalization())\nmodel.add(MaxPooling2D(pool_size=(2, 2)))\nmodel.add(Dropout(0.3))\n\n#3rd Layer\nmodel.add(Conv2D(128, (3, 3), activation='relu'))\nmodel.add(BatchNormalization())\nmodel.add(MaxPooling2D(pool_size=(2, 2)))\nmodel.add(Dropout(0.3))\n\n# Flatten Layer\nmodel.add(Flatten())\n\n#Backed Fully Connected Layers\nmodel.add(Dense(128, activation='relu'))\nmodel.add(BatchNormalization())\nmodel.add(Dropout(0.5))\n\nmodel.add(Dense(64, activation='relu'))\nmodel.add(BatchNormalization())\nmodel.add(Dropout(0.5))\n\n#Out Layer\nmodel.add(Dense(10, activation='softmax'))\n\n#Compiling and training the model\nmodel.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\ntraining = model.fit(x = train.values , y = ytrain_tf, validation_split = 0.20, epochs=30, batch_size=128)\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Evaluation","metadata":{}},{"cell_type":"markdown","source":"## Plotting training accuracy, validation accuracy, training loss and validation loss vs epochs","metadata":{}},{"cell_type":"code","source":"#accuracy\nplt.figure(figsize=(10, 5))\nplt.subplot(1, 2, 1)\nplt.plot(training.history['accuracy'], label='accuracy')\nplt.plot(training.history['val_accuracy'], label='validation Accuracy')\nplt.title('training and validation accuracy')\nplt.xlabel('epochs')\nplt.ylabel('accuracy')\nplt.legend()\n#loss\nplt.subplot(1, 2, 2)\nplt.plot(training.history['loss'], label='training Loss')\nplt.plot(training.history['val_loss'], label='validation Loss')\nplt.title('training and validation Loss')\nplt.xlabel('epochs')\nplt.ylabel('loss')\nplt.legend()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Test accuracy and loss","metadata":{}},{"cell_type":"code","source":"testloss, testacc = model.evaluate(test.values, ytest_tf)\nprint(f'Test Loss: {testloss}')\nprint(f'Test Accuracy: {testacc}')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Classification report","metadata":{}},{"cell_type":"code","source":"yp = np.argmax(model.predict(test.values), axis=1)\nyt = np.argmax(ytest_tf, axis=1)\ncr = classification_report(yt, yp, target_names=[str(i) for i in range(10)])\nprint(cr)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Confusion matrix\n> Confusion matrix between predicted values and actual values","metadata":{}},{"cell_type":"code","source":"cm = confusion_matrix(yt, yp)\nplt.figure(figsize=(10, 10))\nsns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=np.arange(10), yticklabels=np.arange(10))\nplt.title(' onfusion matrix')\nplt.xlabel('predicted labels')\nplt.ylabel('true labels')\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# References\n* ### [Keras blog](https://blog.keras.io/building-powerful-image-classification-models-using-very-little-data.html)\n* ### [Keras 3 API documentation](https://keras.io/api/layers/)\n* ### [CNN Medium blog](https://medium.com/thedeephub/convolutional-neural-networks-a-comprehensive-guide-5cc0b5eae175)\n* ### [Tensorflow guide](https://www.tensorflow.org/tutorials/keras/classification)","metadata":{}}]}